\documentclass[a4paper]{article}

\title{Dependency modelling toolbox}

\author{Leo Lahti\footnote{leo.lahti@iki.fi}, Olli-Pekka Huovilainen, Abhishek Tripathi,\\Ilkka Huopaniemi, and Tommi Suvitaival\\
  Department of Information and Computer Science,\\Aalto University
  School of Science and Technology, Finland}

\usepackage{Sweave}
\usepackage{float}
\begin{document}

\maketitle

%\VignetteIndexEntry{Dependency modelling toolbox (dmt)}

\section{Introduction}

Investigation of dependencies between multiple data sources allows the
discovery of regularities and interactions that are not seen in
individual data sets. The importance of such methods is increasing
with the availability and size of co-occurring data sets in
computational biology, open data initiatives, and in other
domains. Practical, open access implementations of general-purpose
algorithms will help to realize the full potential of these
information sources.

This package provides general-purpose tools for the discovery and
analysis of statistical dependencies between co-occurring data
sources.  The implementations are based on well-established models
such as probabilistic canonical correlation analysis and multi-task
learning \cite{Archambeau06, Bach05, Huopaniemi10, Lahti09mlsp,
  Tripathi08}. Probabilistic framework deals rigorously with the
uncertainties associated with small sample sizes, and allows
incorporation of prior information in the analysis through Bayesian
priors \cite{Lahti09mlsp}. The applicability of the models has been
demonstrated in previous case studies \cite{Huopaniemi10, Lahti09mlsp,
  Tripathi08}.

This is a development version. Your feedback and contributions are
welcome. See the project page at
R-Forge\footnote{http://dmt.r-forge.r-project.org/}, or contact
project authors.

\section{Available functionality}

Current version is divided in three independent modules:

\begin{itemize}
\item dependency-based dimensionality reduction (drCCA\footnote{http://www.cis.hut.fi/projects/mi/software/drCCA/}; \cite{Tripathi08}) 

\item regularized dependency detection (pint\footnote{http://bioconductor.org/packages/release/bioc/html/pint.html}; \cite{Lahti09mlsp})
    
\item multi-way modeling of co-occurrence data (multiWayCCA\footnote{http://www.cis.hut.fi/projects/mi/software/multiWayCCA/}; \cite{Huopaniemi10})
\end{itemize}

We are in the process of integrating the general dependency modeling
algorithms from these application-oriented modules into a unified
dependency modelling toolbox.

\section{Probabilistic CCA with extensions}

\label{sec:framework}

\begin{figure}[htb]
\centering \includegraphics[height=3.5cm, keepaspectratio=TRUE]{cca2}
\caption{Graphical description of the shared latent variable model showing
generation of data sets $X$ and $Y$ from latent shared variable $\mathbf{z}$ 
through $W_x$ and $W_y$}
\label{modelpic}
\end{figure}

Modeling of dependencies is based on the probabilistic canonical
correlation analysis framework \cite{Bach05} and its extensions
\cite{Archambeau06,Lahti09mlsp}. This is a latent variable model that
assumes that the two data sets, \(X\) and \(Y\) can be decomposed in
{\it shared} and {\it data set-specific} components
(Figure~\ref{modelpic}). Our task is to discover these components,
given modeling assumptions.

The shared signal is modeled with a shared latent variable
$\mathbf{z}$. Intuitively, this measures the strength of the shared
signal in each patient. While the variation is shared, it can have
different manifestation in each data set. This is described by
\(W_xz\) and \(W_yz\) where \(W_x\), \(W_y\) indicate how the shared
signal is observed in the individual data sets. Assuming a Gaussian
model for the shared latent variable and data set-specific effects,
this leads to the following model:

\begin{equation}\label{eq:model}             
X \sim \mathcal{N}(W_x\mathbf{z}, \Psi_x)   
\end{equation}
\begin{equation}\label{eq:model2}             
Y \sim \mathcal{N}(W_y\mathbf{z}, \Psi_y)                                      
\end{equation}

The latent variable \(\mathbf{z}\) is assumed to follow standard
multivariate normal distribution, i.e. \(\mathbf{z} ~ N(0, I)\). The
data set-specific effects are described by the covariance matrices
$\Psi_x$ and $\Psi_y$. The model parameters are estimated with an
expectation-maximization (EM) algorithm (see
'fit.dependency.model'). After fitting the model parameters \(W\),
\(\Psi\), a maximum-likelihood estimate of \(\mathbf{z}\) can be
calculated (see 'z.expectation').

\subsection{Special cases}

Particular models are obtained as special cases of the above modeling
framework. This leads to a set of alternative models for dependency
detection, including

\begin{itemize}
  \item probabilistic PCA (pPCA)
  \item probabilistic factor analysis (pFA)  
  \item probabilistic CCA (pCCA)
  \item similarity-constrained probabilistic CCA (pSimCCA)
\end{itemize}

These correspond to different assumptions regarding the structure of
the data set-specific effects and types of dependency. While PCA and
factor analysis are typically used for analysing individual data sets,
they are special cases of the described framework and can therefore
also be used to model dependencies between data sets. For discussion
of the differences between these models, see \cite{Bach05,
  Lahti09mlsp}.

\subsubsection{Probabilistic PCA}

Probabilistic PCA (pPCA) assumes an isotropic model for the data
set-specific effects, with identical covariance matrices:

\begin{equation}\label{eq:pPCA}
\Psi_x = \Psi_y = \sigma I.
\end{equation}

This model is called pPCA since it is identical to concatenating
\(X\), \(Y\), and fitting ordinary probabilistic PCA on the
concatenated data set.

\subsubsection{Probabilistic factor analysis}

Probabilistic factor analysis (pFA) assumes a diagonal model for
\(\Psi_x\), \(\Psi_y\). Note that in general, \(\Psi_x \neq
\Psi_y\). The package also implements a special case with isotropic
but not necessarily identical (as in pPCA) covariance matrices.

This model is called pFA since it is identical to concatenating \(X\),
\(Y\), and fitting ordinary probabilistic factor analysis on the
concatenated data set.

\subsubsection{Probabilistic CCA}

Probabilistic CCA (pCCA) assumes full covariance matrices \(\Psi_x\),
\(\Psi_y\), giving the most detailed model for the data set specific
effects in the described modeling framework. The connection of this
latent variable model and the traditional canonical correlation
analysis has been established in \cite{Bach05}.

\subsubsection{Probabilistic SimCCA}

We also provide toos to guide dependency modeling through Bayesian
priors \cite{Lahti09mlsp}. Similarity-constrained probabilistic CCA
(pSimCCA) imposes a prior on the relation between $W_x$ and
$W_y$. This can be used to guide modeling to focus on certain types of
dependencies, and to avoid overfitting.

The relationship between $W_x$ and $W_y$ is described with \(W_y =
TW_x\). A prior on \(T\) can be used to focus the modeling on certain
types of dependencies. We use matrix normal prior distribution:

\begin{equation}\label{T}
P(T) = N_m(H, \sigma^2_TI, \sigma^2_TI)
\end{equation}

By default, $H = I$ and \(\sigma^2_T = 0\), which results in identical
manifestation of the shared signal in the two data sets: $W_y =
W_x$. This model is denoted pSimCCA in the package. However, the prior
can be loosened by tuning $sigma^2_T$. With $sigma^2_T \rightarrow
\infty$, estimation of $W_x$ and $W_y$ become independent, which leads
to ordinary probabilistic CCA. It is also possible to tune the mean
matrix $H$. This would set a particular relationship between the
manifestations of the shared component in each data set, and
$sigma^2_T$ is again be used to tune the strength of such prior.

\subsection{Measuring dependency}

Dependency between the data sets \(X\), \(Y\) is measured by the ratio
of shared vs. data set-specific signal (see '?dependency.score'):

\begin{equation}\label{depscore}
  \frac{Tr(WW^T)}{Tr(\Psi)}
\end{equation}

\subsection{Functions for dependency modeling}

The package implements the dependency modeling framework (see
'fit.dependency.model'), and provides wrappers for the special cases
of the model.


\section{Dimensionality reduction with CCA}

The drCCA method aims to retain the variation that is shared between
the original data sources, while reducing the dimensionality by
ignoring variation that is specific to any of the data sources
alone. It is assumed that such variation is either noise or at least
less interesting as it is related to a phenomenom not visible in the
other sources, despite those containing measurements of the exact same
objects. The drCCA method is based on utilizing the generalized
canonical correlation analysis to perform a linear projection on the
collection data sets. As the method is completely linear it is fast to
compute for large data sets, making genome-wide fusion possible. The
package includes regularization and tools for selecting the final
dimensionality of the combined data set automatically.


\section{Multi-way multi-view models}

\section{Applications}

Multiple types of genomic observations from the same patients are
increasingly available in biomedical studies, including measurements
of gene- and miRNA expression levels, gene copy number, and
methylation status.  By investigating the dependencies between these
data sets it is possible to discover functional mechanisms and
interactions that are not seen in the individual data sets. For
example, integration of gene expression and copy number has been shown
to reveal cancer-associated chromosomal regions and associated genes
with potential diagnostic, prognostic and clinical impact
\cite{Lahti09mlsp}. 

Applications of the computational models implemented in this package
are considered in application-oriented packages. Here we give a brief
summary of each package, and links to further resources.

\subsection{Preprocessing (drCCA)}

Integration of multiple information sources is an increasingly
important task in bioinformatics applications. Understanding,
predicting or already efficiently exploring the cellular mechanisms
requires information from several sources, such as gene expression,
protein concentrations or transcription factor binding. Combining data
sources, that can in general have very different forms of
representations, is a non-trivial problem, but already partial
solutions are useful. Combining several sources is advantageous also
when using just one type of data, because it reduces the noise which
is often a significant issue in biological experiments that have high
dimensionality but relatively few
samples. drCCA\footnote{http://www.cis.hut.fi/projects/mi/software/drCCA/}
\cite{Tripathi08} provides tools for combining several data sources
with co-occurring samples into a one vectorial data set of low
dimensionality.


\subsection{Microarray data integration (pint)}

pint\footnote{http://bioconductor.org/packages/release/bioc/html/pint.html}
provides tools to integrate gene or micro-RNA expression with DNA copy
number (aCGH) measurements to discover functionally active chromosomal
aberrations \cite{Lahti09mlsp}. The model reveals the affected
chromosomal regions, and indicates the affected genes and
patients. The methods are potentially applicable also to other types
of biomedical data, including methylation, SNPs, alternative splicing
and transcription factor binding.

\subsection{Metabolomics (multiWayCCA)}

multiWayCCA\footnote{http://www.cis.hut.fi/projects/mi/software/multiWayCCA/}
provides tools for multi-way, multi-source modeling of functional
genomics data with particular applications to metabolomics studies
\cite{Huopaniemi10}.

\subsection*{Acknowledgements}

The project is a joint effort by several people: Leo Lahti, Tommi
Suvitaival, Olli-Pekka Huovilainen, Ilkka Huopaniemi, Abhishek
Tripathi, Arto Klami, and Samuel Kaski from the Statistical Machine
Learning and Bioinformatics group at the Department of Information and
Computer Science, Aalto University School of Science and Technology,
Finland. Abhishek Tripathi is with Department of Computer Science,
University of Helsinki, Finland. The authors belong also to Helsinki
Institute for Information Technology HIIT and Adaptive Informatics
Research Centre AIRC.




\bibliographystyle{abbrv}
\bibliography{dmt}

\end{document}
