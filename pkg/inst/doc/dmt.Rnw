\documentclass[a4paper]{article}
\usepackage{amsmath}

\title{Dependency modeling toolkit}

\author{Leo Lahti\footnote{leo.lahti@iki.fi}, Olli-Pekka Huovilainen, and Abhishek Tripathi
  Department of Information and Computer Science,\\Aalto University, Finland}

\usepackage{Sweave}
\usepackage{float}
\begin{document}

\maketitle

%\VignetteIndexEntry{Dependency modeling toolkit}

\section{Introduction}

Dependency modeling between multiple data sources allows the discovery
of regularities and interactions that are not seen in individual data
sets. The need for such methods is increasing with the availability of
co-occurring observations that provide complementary views of the
objects of interest in computational biology, natural language
modeling, neuroinformatics, open data initiatives, social sciences,
and in other domains. Open access implementations of the algorithmic
solutions will help to realize the full potential of these information
sources.

This package provides general-purpose tools for the discovery and
analysis of statistical dependencies between co-occurring measurement
data. The implementations are based on well-established models such as
probabilistic canonical correlation analysis \cite{Archambeau06,
Bach05}. Probabilistic framework deals rigorously with the
uncertainties associated with small sample sizes, and allows
incorporation of prior information in the analysis through Bayesian
priors \cite{Lahti09mlsp}. The applicability of the models has been
demonstrated in previous case studies \cite{Lahti09mlsp, Tripathi08}.
Your feedback and contributions are welcome.\footnote{See the project
page at R-Forge: http://dmt.r-forge.r-project.org/}

\subsection{Installation}

Install dmt from within R using command\\
'install.packages("dmt", repos="http://R-Forge.R-project.org")'

\section{Examples}

To learn dependency models for two data sets, X and Y, use
the fit.dependency.model function: 

<<example1>>=
library(dmt) 
data(modelData) # load example data X, Y
model <- fit.dependency.model(X, Y)
@

The functions provides additional options to tune the dimensionality
of the latent variable and to regularize model parameters. An overview of the
implemented probabilistic models for dependency detection is provided
below. For further options, see help(fit.dependency.model).


\section{Functionality}

\begin{itemize}

\item regularized dependency detection \cite{Bach05, Lahti09mlsp}

\item dependency-based dimensionality reduction \cite{Tripathi08}
  
%\item multi-way modeling of co-occurrence
% data\footnote{http://www.cis.hut.fi/projects/mi/software/multiWayCCA/};
% \cite{Huopaniemi10}. Currently available as example source code only.

\end{itemize}

\subsection{Documentation}

The package implements the dependency modeling framework explained
below (see function 'fit.dependency.model'), and provides wrappers for
the special cases of the model. 

%Currently only online-documentation for the package is available for
%dependency-based dimensionality reduction. See\\
%http://www.cis.hut.fi/projects/mi/software/drCCA/dochtml/00Index.html

\section{Probabilistic dependency modeling framework}
\label{sec:framework}

\begin{figure}[htb]
\centering \includegraphics[height=3.5cm, keepaspectratio=TRUE]{cca2}
\caption{Graphical description of the shared latent variable model showing
generation of data sets $X$ and $Y$ from latent shared variable $\mathbf{z}$ 
through $W_x$ and $W_y$}
\label{modelpic}
\end{figure}

The package \cite{Lahti09mlsp} implements the probabilistic dependency
modeling framework presented in \cite{Bach05} and extensions
\cite{Archambeau06,Klami08,Lahti09mlsp}. The latent variable model
assumes that the two data sets, \(X\) and \(Y\) can be decomposed in
{\it shared} and {\it data set-specific} components
(Figure~\ref{modelpic}). Our tools help to discover these components,
given modeling assumptions.

The shared signal is modeled with a latent variable $\mathbf{z}$.
Intuitively, this measures the strength of the shared signal in each
patient. Shared signal can have different manifestation in each data
set, described by \(W_xz\) and \(W_yz\) where \(W_x\), \(W_y\).
Assuming a standard Gaussian model for the shared latent variable
\(\mathbf{z} \sim N(0, I)\) and data set-specific effects, this leads
to the following model:

\begin{equation}\label{eq:model}             
\begin{aligned}
  X \sim W_x\mathbf{z} + \varepsilon_x\\
  Y \sim W_y\mathbf{z} + \varepsilon_y \\
\varepsilon_. \sim \mathcal{N}(0, \Psi_.)\\
\mathbf{z} \sim \mathcal{N}(0, I)   
\end{aligned}
\end{equation}

The data set-specific effects are modelled by the covariance matrices
$\Psi_x$, $\Psi_y$. Model parameters are estimated with an EM
algorithm.

\subsection{Special cases}

Special cases of the model include probabilistic versions of canonical
correlation analysis, factor analysis, and principal component
analysis, and regularized variants.

Probabilistic CCA (pCCA) assumes full covariance matrices \(\Psi_x\),
\(\Psi_y\). This gives the most detailed model for the data set
specific effects. The connection of this latent variable model and the
traditional canonical correlation analysis has been established in
\cite{Bach05}.

Probabilistic factor analysis (pFA) is obtained with diagonal
covariances \(\Psi_x\), \(\Psi_y\). In addition, a special case is
implemented where each covariance matrix \(\Psi_.\) is isotropic but
not necessarily identical (as would be the case in pPCA). This model
is identical to concatenating \(X\), \(Y\), and fitting ordinary
probabilistic factor analysis on the concatenated data set. The
structure of the covariances is simpler than in pCCA. This regularizes
the solution and can potentially reduce overfitting in some
applications.

Probabilistic PCA (pPCA) is obtained with identical isotropic
covariances for the data set-specific effects: \(\Psi_x = \Psi_y =
\sigma I\). This model is identical to concatenating \(X\), \(Y\), and
fitting ordinary probabilistic PCA on the concatenated data.

\subsection{Regularized dependency modelling}

We provide toos to guide dependency modeling through Bayesian priors
\cite{Lahti09mlsp}. Prior on the relation between $W_x$ and $W_y$ can be
used to guide modeling to focus on certain types of dependencies, and
to avoid overfitting. The relationship is described through \(W_y =
TW_x\). We use matrix normal prior distribution: \(P(T)
= N_m(H, \sigma^2_TI, \sigma^2_TI)\). By default, $H = I$ and
\(\sigma^2_T = 0\), giving $W_y = W_x$. This model is denoted
pSimCCA in the package. The prior can be loosened by tuning
$sigma^2_T$. With $sigma^2_T \rightarrow \infty$, estimation of $W_x$
and $W_y$ become independent, yielding ordinary probabilistic
CCA. It is also possible to tune the mean matrix $H$. This would set a
particular relationship between the manifestations of the shared
component in each data set, and \(sigma^2_T\) is again be used to tune
the strength of such prior.

\section{Dependency-based dimensionality reduction}

The drCCA \cite{Tripathi08} method can be used for dependency-based
dimensionality reduction that retains the variation shared between the
original data sources, while reducing data set-specific effects. The
approach utilizes generalized canonical correlation analysis to
perform a linear projection on the collection of data sets. Linearity
makes it fast on large data sets. The package includes regularization
and tools to select the final dimensionality of the combined data set
automatically. More examples will be added later.

%\subsection{Applications}
%
%For applications in functional genomics, see \cite{Lahti09mlsp,
%Tripathi08}, and the associated
%pint\footnote{http://bioconductor.org/packages/release/bioc/html/pint.html}
%BioConductor package, which provides application-specific tools for
%genome analysis. 

%\section{Multi-way multi-view models (multiWayCCA)}
%multiWayCCA\footnote{http://www.cis.hut.fi/projects/mi/software/multiWayCCA/}
%provides tools for multi-way, multi-source modeling. This is
%particularly usefule for simultaneous multi-way (anova-type) modelling
%of multiple related data sources. For details, see the original paper
%\cite{Huopaniemi10}.

%\subsection{Installing \& documentation of multiWayCCA}
%Download the
%source\footnote{http://www.cis.hut.fi/projects/mi/software/multiWayCCA/multiWayCCA-package-100326.zip}.
%Then uncompress the folder; readme.txt in the uncompressed folder
%contains instructions for running the analysis. For documentation and
%examples, see the readme.txt file included in the package.

\section{Details}

\begin{itemize}
\item {\it Licensing terms:} the package is licensed under FreeBSD open software license
\item {\it Citing DMT:} Please cite \cite{Lahti10icml, Lahti10thesis} when using the package
\end{itemize}

This document was written using:

<<details>>=
sessionInfo()
@


\subsection*{Acknowledgements}

The project is a joint effort by several people: Leo Lahti, Olli-Pekka
Huovilainen, and Abhishek Tripathi from the Statistical Machine
Learning and Bioinformatics group at the Department of Information and
Computer Science, Aalto University School of Science and Technology,
Finland. Abhishek Tripathi is with Department of Computer Science,
University of Helsinki, Finland. The authors belong also to Helsinki
Institute for Information Technology HIIT and Adaptive Informatics
Research Centre AIRC.

%\bibliographystyle{unsrt}
%\bibliography{dmt}

\begin{thebibliography}{1}

\bibitem{Archambeau06}
C{\'e}dric Archambeau, Nicolas Delannay, and Michel Verleysen.
\newblock Robust probabilistic projections.
\newblock In W.W. Cohen and A.~Moore, editors, {\em Proceedings of the 23rd
  International conference on machine learning}, pages 33--40. ACM, 2006.

\bibitem{Bach05}
Francis~R. Bach and Michael~I. Jordan.
\newblock A probabilistic interpretation of canonical correlation analysis.
\newblock Technical Report 688, Department of Statistics, University of
  California, Berkeley, 2005.

%\bibitem{Huopaniemi10}
%Ilkka Huopaniemi, Tommi Suvitaival, Janne Nikkil\"{a}, Matej Ore\u{s}ic, and
%  Samuel Kaski.
%\newblock Multivariate multi-way analysis of multi-source data.
%\newblock {\em Bioinformatics}, 2010.
%\newblock (ISMB 2010, to appear).

\bibitem{Lahti09mlsp}
Leo Lahti, Samuel Myllykangas, Sakari Knuutila, and Samuel Kaski.
\newblock Dependency detection with similarity constraints.
\newblock In {\em Proc. MLSP'09 IEEE International Workshop on Machine Learning
  for Signal Processing}, IEEE, Piscataway, NJ, 2009.

\bibitem{Lahti10thesis}                                           
Leo Lahti (2010).                                     
\newblock Probabilistic analysis of the human transcriptome with side information.                       
\newblock PhD thesis. Aalto University School of Science and Technology, Department of information and Computer Science, Espoo, Finland, 2010. 
\newblock http://lib.tkk.fi/Diss/2010/isbn9789526033686/        

\bibitem{Lahti10icml}                                           
Leo Lahti {\it et al.} (2010).                                     
\newblock Dependency modeling toolkit.
\newblock International Conference on Machine Learning (ICML-2010). Workshop on Machine Learning Open Source Software. Haifa, Israel, 2010.
\newblock Project url: http://dmt.r-forge.r-project.org
 

\bibitem{Tripathi08}
Arto~Klami Abhishek~Tripathi and Samuel Kaski.
\newblock Simple integrative preprocessing preserves what is shared in data
  sources.
\newblock {\em BMC Bioinformatics}, 9(111), 2008.

\bibitem{Klami08}
Arto Klami and Samuel Kaski.
\newblock Probabilistic approach to detecting dependencies between data sets.
\newblock {\em Neurocomputing}, 72(1-3):39--46, 2008.

\end{thebibliography}


\end{document}
